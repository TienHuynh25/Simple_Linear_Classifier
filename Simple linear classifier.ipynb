{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Classifier\n",
    "--------------------------------------------\n",
    "## This model can classify image of number 3 or number 7 from MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting images from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack all images of 3 in trainning set on top of each other, and do the same for 7 and images in valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6131, 28, 28]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'train'/'3').ls()])\n",
    "stacked_threes = stacked_threes.float()/255\n",
    "\n",
    "stacked_sevens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'train'/'7').ls()])\n",
    "stacked_sevens = stacked_threes.float()/255\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1010, 28, 28]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_threes = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_threes = valid_threes.float()/255\n",
    "\n",
    "valid_sevens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_sevens = valid_threes.float()/255\n",
    "valid_threes.shape, valid_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our independent variables `X`. These are all images in our trainning set, and they also will be changed from rank-3 tensor to rank-2 tensor.\n",
    "We also need label for our images. Number `1` will represent for 3s and `0` will be for 7s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12262, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group train_x and train_y into a tuple of (x,y) to have a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for `valid set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_threes, valid_sevens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to initilize random weight for every pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear1 will return predictions by using matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our loss function which measures the distance between `predictions` and `targets`  \n",
    "*The sigmoid function is a function that always outputs a number between 0 and 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that calculates the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb,yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_epoch will calculate gradients and also update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will calculate our validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb \n",
    "    #if preds is greater than 0.5 it means the prediction is number 3\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this will do the job for the whole batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accuracies = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accuracies).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Phase\n",
    "------------------------------\n",
    "### The most basic way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Dataloader` to create mini-batches from our `Dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! let's train for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9907"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr  = 1 #we set learning rate to 1\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train it few more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9956 0.9985 0.999 0.9995 0.9995 0.9995 0.9995 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the second trial(including Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional functions and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our `Optimizer class` which will help us handle `parameter` and `lr`, as well as calculating `gradient` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "    \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "    \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's update `train_epoch` method using `Optimizer` now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanna have a method to train our model in many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we subtitute our simple funtion(linear1) for Pytorch's nn.Linear module. (*from the PyTorch nn.Module class*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get parameters from PyTorch module by using `paramters` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape #(weights and biasis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8296"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or We can also use `SGD` class from fastai in exchange for `BasicOptim` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-built functions and classes from fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.115182</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048163</td>\n",
       "      <td>0.013874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025283</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015278</td>\n",
       "      <td>0.007104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010348</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we need to create a DataLoaders, by passing in our training and validation DataLoaders\n",
    "dls = DataLoaders(dl, valid_dl)\n",
    "#learner(dataloaders, initial parameter, optimizer or SGD, loss function, metrics)\n",
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "#fastai also provides Learner.fit, which we can use instead of train_model.\n",
    "learn.fit(20, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Nonlinearity(optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `single linear layer`, we try to add one more linear layer to our architecture(model) with a `nonlinearity` in between.  \n",
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.335540</td>\n",
       "      <td>0.210051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.243253</td>\n",
       "      <td>0.140759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176641</td>\n",
       "      <td>0.095939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.126424</td>\n",
       "      <td>0.066544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090038</td>\n",
       "      <td>0.047311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.064576</td>\n",
       "      <td>0.034651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>0.026194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.035192</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021280</td>\n",
       "      <td>0.013417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.014209</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.011971</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.010253</td>\n",
       "      <td>0.007262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.008907</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.004692</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fafe9af3bb0>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>0.033004</td>\n",
       "      <td>0.991659</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                   loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
