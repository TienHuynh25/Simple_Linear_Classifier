{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Classifier\n",
    "--------------------------------------------\n",
    "## This model can classify image of number 3 or number 7 from MNIST database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting images from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack all images of 3 in trainning set on top of each other, and do the same for 7 and images in valid set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6131, 28, 28]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_threes = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'train'/'3').ls()])\n",
    "stacked_threes = stacked_threes.float()/255\n",
    "\n",
    "stacked_sevens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'train'/'7').ls()])\n",
    "stacked_sevens = stacked_threes.float()/255\n",
    "stacked_threes.shape, stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1010, 28, 28]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_threes = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_threes = valid_threes.float()/255\n",
    "\n",
    "valid_sevens = torch.stack([tensor(Image.open(o)) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_sevens = valid_threes.float()/255\n",
    "valid_threes.shape, valid_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our independent variables `X`. These are all images in our trainning set, and they also will be changed from rank-3 tensor to rank-2 tensor.\n",
    "We also need label for our images. Number `1` will represent for 3s and `0` will be for 7s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12262, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group train_x and train_y into a tuple of (x,y) to have a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = list(zip(train_x, train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do the same for `valid set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_threes, valid_sevens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_threes) + [0]*len(valid_sevens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to initilize random weight for every pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear1 will return predictions by using matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear1(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our loss function which measures the distance between `predictions` and `targets`  \n",
    "*The sigmoid function is a function that always outputs a number between 0 and 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a function that calculates the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb,yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_epoch will calculate gradients and also update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will calculate our validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb \n",
    "    #if preds is greater than 0.5 it means the prediction is number 3\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then this will do the job for the whole batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accuracies = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    return round(torch.stack(accuracies).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Phase\n",
    "------------------------------\n",
    "### The most basic way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize our parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `Dataloader` to create mini-batches from our `Dataset` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dset, batch_size=256)\n",
    "xb,yb = first(dl)\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! let's train for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9756"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr  = 1 #we set learning rate to 1\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train it few more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9976 0.9995 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the second trial(including Optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional functions and classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our `Optimizer class` which will help us handle `parameter` and `lr`, as well as calculating `gradient` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "    \n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "    \n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's update `train_epoch` method using `Optimizer` now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also wanna have a method to train our model in many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we subtitute our simple funtion(linear1) for Pytorch's nn.Linear module. (*from the PyTorch nn.Module class*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(28*28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get parameters from PyTorch module by using `paramters` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b = linear_model.parameters()\n",
    "w.shape,b.shape #(weights and biasis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BasicOptim(linear_model.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or We can also use `SGD` class from fastai in exchange for `BasicOptim` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28, 1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pre-built functions and classes from fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.115105</td>\n",
       "      <td>0.027872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048126</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015264</td>\n",
       "      <td>0.007102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010336</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.004160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003447</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.002322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#we need to create a DataLoaders, by passing in our training and validation DataLoaders\n",
    "dls = DataLoaders(dl, valid_dl)\n",
    "#learner(dataloaders, initial parameter, optimizer or SGD, loss function, metrics)\n",
    "learn = Learner(dls, nn.Linear(28*28, 1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "#fastai also provides Learner.fit, which we can use instead of train_model.\n",
    "learn.fit(20, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Nonlinearity(optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `single linear layer`, we try to add one more linear layer to our architecture(model) with a `nonlinearity` in between.  \n",
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "               loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.344474</td>\n",
       "      <td>0.209642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.242716</td>\n",
       "      <td>0.135160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.169949</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115691</td>\n",
       "      <td>0.055779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077897</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037128</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015920</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012853</td>\n",
       "      <td>0.008535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009020</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.007775</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006018</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.003430</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.003186</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f089bbe97f0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='175' class='' max='193' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      90.67% [175/193 00:12<00:01 0.1123]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = cnn_learner(dls, resnet18, pretrained=False,\n",
    "                   loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
